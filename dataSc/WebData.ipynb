{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But soft what light through yonder window breaks\n",
      "It is the east and Juliet is the sun\n",
      "Arise fair sun and kill the envious moon\n",
      "Who is already sick and pale with grief\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "man_a = urllib.request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "for linea in man_a:\n",
    "    print(linea.decode().strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'But': 1, 'soft': 1, 'what': 1, 'light': 1, 'through': 1, 'yonder': 1, 'window': 1, 'breaks': 1, 'It': 1, 'is': 3, 'the': 3, 'east': 1, 'and': 3, 'Juliet': 1, 'sun': 2, 'Arise': 1, 'fair': 1, 'kill': 1, 'envious': 1, 'moon': 1, 'Who': 1, 'already': 1, 'sick': 1, 'pale': 1, 'with': 1, 'grief': 1}\n"
     ]
    }
   ],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "\n",
    "man_a = urllib.request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "\n",
    "contadores = dict()\n",
    "for linea in man_a:\n",
    "    palabras = linea.decode().split()\n",
    "    for palabra in palabras:\n",
    "        contadores[palabra] = contadores.get(palabra, 0) + 1\n",
    "print(contadores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.dr-chuck.com/page2.htm\n"
     ]
    }
   ],
   "source": [
    "from bs4 import  BeautifulSoup\n",
    "\n",
    "url=input('Enter - ')\n",
    "html=urllib.request.urlopen(url).read()\n",
    "soup =BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# retieve all of the anchor tags\n",
    "tags = soup(\"a\")\n",
    "for  tag in tags:\n",
    "    print(tag.get('href', None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = urllib.request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL encontrada: http://www.dr-chuck.com\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "html_text = '<p>Please click <a href=\"http://www.dr-chuck.com\">here</a></p>'\n",
    "\n",
    "# Expresión regular para extraer la URL del atributo href\n",
    "pattern = r'href=\"(.+)\"'\n",
    "\n",
    "# Buscar la URL usando la regex\n",
    "match = re.search(pattern, html_text)\n",
    "\n",
    "# Si se encuentra una coincidencia, obtener el valor de la URL\n",
    "if match:\n",
    "    url = match.group(1)\n",
    "    print(\"URL encontrada:\", url)\n",
    "else:\n",
    "    print(\"URL no encontrada\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome Mario Daniel Rodriguez Casallas from Using Python to Access Web Data\n",
    "\n",
    "Scraping Numbers from HTML using BeautifulSoup In this assignment you will write a Python program similar to http://www.py4e.com/code3/urllink2.py. The program will use urllib to read the HTML from the data files below, and parse the data, extracting numbers and compute the sum of the numbers in the file.\n",
    "\n",
    "We provide two files for this assignment. One is a sample file where we give you the sum for your testing and the other is the actual data you need to process for the assignment.\n",
    "\n",
    "    Sample data: http://py4e-data.dr-chuck.net/comments_42.html (Sum=2553)\n",
    "    Actual data: http://py4e-data.dr-chuck.net/comments_1968702.html (Sum ends with 95)\n",
    "\n",
    "You do not need to save these files to your folder since your program will read the data directly from the URL. Note: Each student will have a distinct data url for the assignment - so only use your own data url for analysis.\n",
    "\n",
    "Data Format\n",
    "\n",
    "The file is a table of names and comment counts. You can ignore most of the data in the file except for lines like the following:\n",
    "\n",
    "<tr><td>Modu</td><td><span class=\"comments\">90</span></td></tr>\n",
    "<tr><td>Kenzie</td><td><span class=\"comments\">88</span></td></tr>\n",
    "<tr><td>Hubert</td><td><span class=\"comments\">87</span></td></tr>\n",
    "\n",
    "You are to find all the <span> tags in the file and pull out the numbers from the tag and sum the numbers.\n",
    "\n",
    "Look at the sample code provided. It shows how to find all of a certain kind of tag, loop through the tags and extract the various aspects of the tags.\n",
    "\n",
    "...\n",
    "# Retrieve all of the anchor tags\n",
    "tags = soup('a')\n",
    "for tag in tags:\n",
    "   # Look at the parts of a tag\n",
    "   print 'TAG:',tag\n",
    "   print 'URL:',tag.get('href', None)\n",
    "   print 'Contents:',tag.contents[0]\n",
    "   print 'Attrs:',tag.attrs\n",
    "\n",
    "You need to adjust this code to look for span tags and pull out the text content of the span tag, convert them to integers and add them up to complete the assignment.\n",
    "\n",
    "Sample Execution\n",
    "\n",
    "$ python3 solution.py\n",
    "Enter - http://py4e-data.dr-chuck.net/comments_42.html\n",
    "Count 50\n",
    "Sum 2...\n",
    "\n",
    "Turning in the Assignment\n",
    "Enter the sum from the actual data and your Python code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 50\n",
      "Sum: 2595\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Solicitar la URL\n",
    "url = input(\"Enter URL: \")\n",
    "\n",
    "# Leer el contenido HTML de la URL\n",
    "html = urllib.request.urlopen(url).read()\n",
    "\n",
    "# Analizar el HTML con BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Encontrar todas las etiquetas <span> con la clase 'comments'\n",
    "span_tags = soup.find_all('span', class_='comments')\n",
    "\n",
    "# Inicializar la suma\n",
    "total_sum = 0\n",
    "\n",
    "# Iterar sobre las etiquetas <span> y sumar los números\n",
    "for span in span_tags:\n",
    "    # Extraer el contenido de texto de la etiqueta <span>\n",
    "    number = int(span.text)\n",
    "    # Sumar el número\n",
    "    total_sum += number\n",
    "\n",
    "# Imprimir la suma total\n",
    "print(f\"Count: {len(span_tags)}\")\n",
    "print(f\"Sum: {total_sum}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
